{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import search.unionable_table_search as uts\n",
    "import search.joinable_table_search as jts\n",
    "import post_processing.filtering_reranking as fr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](pipeline_illustration.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unionable Table Search \n",
    "Once the data lake embeddings have been computed following the instructions described in [here](embedding_computation/README.md), we can execute unionable table search. <br>\n",
    "In this demo, we have already computed embeddings for SANTOS data lake provided with SANTOS benchmark with the following configurations [#0](embedding_computation/experiments.md). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Faiss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datalake_embeddings = '/Users/alaaalmutawa/Documents/Thesis/extending_hytrel/output/hytrel_embedding/santos/hytrel_datalake_columns_0.pkl'\n",
    "query_embeddings = '/Users/alaaalmutawa/Documents/Thesis/extending_hytrel/output/hytrel_embedding/santos/hytrel_query_columns_0.pkl'\n",
    "k = 10\n",
    "## select a query dataset\n",
    "with open(query_embeddings, 'rb') as f:\n",
    "    query_columns_hytrel = pickle.load(f)\n",
    "with open(datalake_embeddings, 'rb') as f:\n",
    "    datalake_columns_hytrel = pickle.load(f)\n",
    "query_table = query_columns_hytrel[0] ## corresponding to 'cihr_co-applicant_b.csv'\n",
    "candidates, build_duration, query_duration = uts.approximate_unionable_dataset_search([query_columns_hytrel[0]], datalake_columns_hytrel,k,compress_method='max')\n",
    "candidates = candidates['cihr_co-applicant_b.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate in 1 place: cihr_co-applicant_b.csv\n",
      "candidate in 2 place: cihr_co-applicant_9.csv\n",
      "candidate in 3 place: cihr_co-applicant_7.csv\n",
      "candidate in 4 place: cihr_co-applicant_6.csv\n",
      "candidate in 5 place: cihr_co-applicant_8.csv\n",
      "candidate in 6 place: cihr_co-applicant_3.csv\n",
      "candidate in 7 place: cihr_co-applicant_5.csv\n",
      "candidate in 8 place: cihr_co-applicant_1.csv\n",
      "candidate in 9 place: cihr_co-applicant_0.csv\n",
      "candidate in 10 place: cihr_co-applicant_2.csv\n",
      "Index build duration: 0.0024347305297851562\n",
      "Query duration: 0.000102996826171875\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(candidates)):\n",
    "    print(f'candidate in {i+1} place: {candidates[i]}')\n",
    "\n",
    "print(f'Index build duration: {build_duration}')\n",
    "print(f'Query duration: {query_duration}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering-based search \n",
    "Once the embeddings have been computed. We can preform hierarchal clustering on the computed data lake embeddings. Instructions to compute heirarchal clustering can be found [here](clustering/) <br>\n",
    "In this demo, we have ran clustering on column embeddings with configuration [0](/embedding_computation/experiments.md) and cluster count of [811](clustering/experiments.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = '/Users/alaaalmutawa/Documents/Thesis/extending_hytrel/output/clustering/santos/clustering_811_santos_run_id_0.pkl'\n",
    "with open(clustering, 'rb') as f:\n",
    "    clustering_result = pickle.load(f)\n",
    "datalake = list(set(clustering_result['dataset'].unique()))\n",
    "query = 'cihr_co-applicant_b.csv'\n",
    "k = 10\n",
    "res = uts.unionable_table_search_using_clustering([query], datalake, clustering_result,k)\n",
    "candidates = res[query]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate in 1 place: cihr_co-applicant_b.csv\n",
      "candidate in 2 place: cihr_co-applicant_6.csv\n",
      "candidate in 3 place: cihr_co-applicant_0.csv\n",
      "candidate in 4 place: cihr_co-applicant_1.csv\n",
      "candidate in 5 place: cihr_co-applicant_3.csv\n",
      "candidate in 6 place: cihr_co-applicant_4.csv\n",
      "candidate in 7 place: cihr_co-applicant_9.csv\n",
      "candidate in 8 place: cihr_co-applicant_5.csv\n",
      "candidate in 9 place: cihr_co-applicant_7.csv\n",
      "candidate in 10 place: cihr_co-applicant_2.csv\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(candidates)):\n",
    "    print(f'candidate in {i+1} place: {candidates[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joinable Table Search\n",
    "Once the data lake embeddings have been computed following the instructions described in [here](embedding_computation/README.md), we can execute unionable table search. <br>\n",
    "In this demo, we have already computed embeddings for NextiaJD testbedS data lake provided with NextiaJD benchmark with the following configurations [#4](embedding_computation/experiments.md). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_datalake_columns:  2553\n",
      "build regular index using faiss\n",
      "number of queries: 1\n"
     ]
    }
   ],
   "source": [
    "datalake_embeddings = '/Users/alaaalmutawa/Documents/Thesis/extending_hytrel/output/hytrel_embedding/nextiajd/testbedS/hytrel_datalake_columns_4.pkl'\n",
    "query_embeddings = '/Users/alaaalmutawa/Documents/Thesis/extending_hytrel/output/hytrel_embedding/nextiajd/testbedS/hytrel_query_columns_4.pkl'\n",
    "with open(query_embeddings, 'rb') as f:\n",
    "    query_columns_hytrel = pickle.load(f)\n",
    "with open(datalake_embeddings, 'rb') as f:\n",
    "    datalake_columns_hytrel = pickle.load(f)\n",
    "\n",
    "res, build_duration, query_duration = jts.joinable_dataset_search([query_columns_hytrel[61]], datalake_columns_hytrel,1000,'testbedS')\n",
    "candidates = res[('agri-environmental-indicators-emissions-by-sector.csv',\n",
    "  'Area')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate in 1 place: ('emissions_agriculture_energy_e_all_data_norm.csv', 'Country')\n",
      "candidate in 2 place: ('global-greenhouse-gas-emissions0.csv', 'Country')\n",
      "candidate in 3 place: ('global-innovation-index-2015.csv', 'COUNTRY_NAME')\n",
      "candidate in 4 place: ('population-estimates-and-projections-1960-2050.csv', 'COUNTRY')\n",
      "candidate in 5 place: ('global-greenhouse-gas-emissions.csv', 'Country')\n",
      "candidate in 6 place: ('listings_summary.csv', 'host_name')\n",
      "candidate in 7 place: ('makemytrip_com-travel_sample.csv', 'city')\n",
      "candidate in 8 place: ('listings_detailed.csv', 'host_name')\n",
      "candidate in 9 place: ('listings_summary.csv', 'host_neighbourhood')\n",
      "candidate in 10 place: ('listings_summary.csv', 'neighbourhood')\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(candidates)):\n",
    "    print(f'candidate in {i+1} place: {candidates[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-processing: Filtering, and Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running LSH ensemble for query ('agri-environmental-indicators-emissions-by-sector.csv', 'Area')\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/agri-environmental-indicators-emissions-by-sector.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/emissions_agriculture_energy_e_all_data_norm.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/global-greenhouse-gas-emissions0.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/global-innovation-index-2015.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/population-estimates-and-projections-1960-2050.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/global-greenhouse-gas-emissions.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/listings_summary.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/makemytrip_com-travel_sample.csv\n",
      "delimiter: ,\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/listings_detailed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alaaalmutawa/Documents/Thesis/extending_hytrel/post_processing/filtering_reranking.py:26: DtypeWarning: Columns (43,61,62) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/listings_summary.csv\n",
      "file_path: /Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets/listings_summary.csv\n"
     ]
    }
   ],
   "source": [
    "datalake_source = '/Users/alaaalmutawa/Documents/Thesis/nextiajd/testbedS/datasets'\n",
    "filtered,overlap_est = fr.run_lsh_ensemble(datalake_source, res, num_perm=256, threshold=0.5, num_part=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('agri-environmental-indicators-emissions-by-sector.csv',\n",
       "  'Area'): [('emissions_agriculture_energy_e_all_data_norm.csv',\n",
       "   'Country'), ('global-greenhouse-gas-emissions0.csv', 'Country'), ('global-greenhouse-gas-emissions.csv',\n",
       "   'Country'), ('global-innovation-index-2015.csv', 'COUNTRY_NAME')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reranked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate in 1 place: ('emissions_agriculture_energy_e_all_data_norm.csv', 'Country') in the original list ('emissions_agriculture_energy_e_all_data_norm.csv', 'Country')\n",
      "candidate in 2 place: ('global-greenhouse-gas-emissions0.csv', 'Country') in the original list ('global-greenhouse-gas-emissions0.csv', 'Country')\n",
      "candidate in 3 place: ('global-greenhouse-gas-emissions.csv', 'Country') in the original list ('global-innovation-index-2015.csv', 'COUNTRY_NAME')\n",
      "candidate in 4 place: ('global-innovation-index-2015.csv', 'COUNTRY_NAME') in the original list ('population-estimates-and-projections-1960-2050.csv', 'COUNTRY')\n",
      "candidate in 5 place: ('population-estimates-and-projections-1960-2050.csv', 'COUNTRY') in the original list ('global-greenhouse-gas-emissions.csv', 'Country')\n",
      "candidate in 6 place: ('listings_summary.csv', 'host_name') in the original list ('listings_summary.csv', 'host_name')\n",
      "candidate in 7 place: ('makemytrip_com-travel_sample.csv', 'city') in the original list ('makemytrip_com-travel_sample.csv', 'city')\n",
      "candidate in 8 place: ('listings_detailed.csv', 'host_name') in the original list ('listings_detailed.csv', 'host_name')\n",
      "candidate in 9 place: ('listings_summary.csv', 'host_neighbourhood') in the original list ('listings_summary.csv', 'host_neighbourhood')\n",
      "candidate in 10 place: ('listings_summary.csv', 'neighbourhood') in the original list ('listings_summary.csv', 'neighbourhood')\n"
     ]
    }
   ],
   "source": [
    "reranked = fr.rank_table(overlap_est)\n",
    "candidates_reranked = reranked[('agri-environmental-indicators-emissions-by-sector.csv',\n",
    "  'Area')]\n",
    "for i in range(len(candidates_reranked)):\n",
    "    print(f'candidate in {i+1} place: {candidates_reranked[i]} in the original list {candidates[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_info423_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
